{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"collapsed_sections":["r094Dy18OMsg","RP0iY45PtSFW","rex6xev5qP-G","pUYfZKNlhSFn"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Real-time object detection in webcam video stream using Ultralytics YOLOv8\n","\n","This is a refactored version of an older, YOLOv3-compatible [notebook][older_notebook] which no longer works.\n","\n","Instructions:\n","\n","* Run `Runtime` > `Run all` (or press <kbd>Ctrl</kbd> <kbd>F9</kbd>) to run all cells.\n","* Allow access to the webcam, if asked.\n","* To stop the webcam capture, click the red text or the picture.\n","\n","Resources:\n","* Ultralytics [documentation][ultralytics_doc] for object detection.\n","* Google Colab [documentation][ipython_display_doc] for executing JavaScript from Python for tasks such as webcam capture, etc.\n","\n","Author: [Kiril Isakov][kisakov_linkedin] ([kirisakow][kirisakow_github])\n","\n","[kisakov_linkedin]: https://www.linkedin.com/in/kisakov/\n","[kirisakow_github]: https://github.com/kirisakow\n","[older_notebook]: https://github.com/vindruid/yolov3-in-colab/blob/aaac930911e18826c560d3156220cedb8726b8c7/yolov3_streaming_webcam.ipynb\n","[ipython_display_doc]: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n","[ultralytics_doc]: https://docs.ultralytics.com/tasks/detect/"],"metadata":{"id":"VPMjpFmrhUAc"}},{"cell_type":"markdown","source":["## 0. Prerequisites"],"metadata":{"id":"r094Dy18OMsg"}},{"cell_type":"markdown","source":["### 0.1. Install and initialize libraries and constants"],"metadata":{"id":"RP0iY45PtSFW"}},{"cell_type":"code","source":["! pip install --upgrade --quiet ultralytics"],"metadata":{"id":"--kKX4f9WlAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 1. Mount Google Drive ###\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"id":"yVxR6nB9eCXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from base64 import b64decode, b64encode\n","from google.colab.output import eval_js\n","from IPython.display import display, Javascript\n","from PIL import Image\n","from ultralytics import YOLO\n","from ultralytics.engine.results import Results\n","import io\n","import numpy as np\n","\n","# Caminho do modelo treinado\n","model_path = \"/content/gdrive/MyDrive/Sistema_de_Visão/yolov8/Cashew_nut/Train_CashewNut/runs/detect/train/weights/best.pt\"\n","\n","MODEL_NAMES = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']\n","#PRE_TRAINED_MODEL = YOLO(MODEL_NAMES[0])\n","PRE_TRAINED_MODEL = YOLO(model_path)\n","IMG_SHAPE = [640, 480]\n","IMG_QUALITY = 0.8"],"metadata":{"id":"XAgO_ab-roQ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rex6xev5qP-G"},"source":["### 0.2. Define JavaScript functions to capture webcam stream, and to be called by Python"]},{"cell_type":"code","metadata":{"id":"7OYmjeF-edKE"},"source":["def start_stream():\n","    js = Javascript(f'''\n","    const IMG_SHAPE = {IMG_SHAPE};\n","    const IMG_QUALITY = {IMG_QUALITY};\n","    ''' + '''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","        stream.getVideoTracks()[0].stop();\n","        video.remove();\n","        div.remove();\n","        video = null;\n","        div = null;\n","        stream = null;\n","        imgElement = null;\n","        captureCanvas = null;\n","        labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","        if (!shutdown) {\n","            window.requestAnimationFrame(onAnimationFrame);\n","        }\n","        if (pendingResolve) {\n","            var result = \"\";\n","            if (!shutdown) {\n","                captureCanvas.getContext('2d').drawImage(video, 0, 0, IMG_SHAPE[0], IMG_SHAPE[1]);\n","                result = captureCanvas.toDataURL('image/jpeg', IMG_QUALITY)\n","            }\n","            var lp = pendingResolve;\n","            pendingResolve = null;\n","            lp(result);\n","        }\n","    }\n","\n","    async function createDom() {\n","        if (div !== null) {\n","            return stream;\n","        }\n","\n","        div = document.createElement('div');\n","        div.style.border = '2px solid black';\n","        div.style.padding = '3px';\n","        div.style.width = '100%';\n","        div.style.maxWidth = '600px';\n","        document.body.appendChild(div);\n","\n","        const modelOut = document.createElement('div');\n","        modelOut.innerHTML = \"<span>Status: </span>\";\n","        labelElement = document.createElement('span');\n","        labelElement.innerText = 'No data';\n","        labelElement.style.fontWeight = 'bold';\n","        modelOut.appendChild(labelElement);\n","        div.appendChild(modelOut);\n","\n","        video = document.createElement('video');\n","        video.style.display = 'block';\n","        video.width = div.clientWidth - 6;\n","        video.setAttribute('playsinline', '');\n","        video.onclick = () => { shutdown = true; };\n","        stream = await navigator.mediaDevices.getUserMedia(\n","            {video: { facingMode: \"environment\"}});\n","        div.appendChild(video);\n","\n","        imgElement = document.createElement('img');\n","        imgElement.style.position = 'absolute';\n","        imgElement.style.zIndex = 1;\n","        imgElement.onclick = () => { shutdown = true; };\n","        div.appendChild(imgElement);\n","\n","        const instruction = document.createElement('div');\n","        instruction.innerHTML =\n","            '<span style=\"color: red; font-weight: bold;\">' +\n","            'When finished, click here or on the video to stop this demo</span>';\n","        div.appendChild(instruction);\n","        instruction.onclick = () => { shutdown = true; };\n","\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        captureCanvas = document.createElement('canvas');\n","        captureCanvas.width = IMG_SHAPE[0]; //video.videoWidth;\n","        captureCanvas.height = IMG_SHAPE[1]; //video.videoHeight;\n","        window.requestAnimationFrame(onAnimationFrame);\n","\n","        return stream;\n","    }\n","    async function takePhoto(label, imgData) {\n","        if (shutdown) {\n","            removeDom();\n","            shutdown = false;\n","            return '';\n","        }\n","\n","        var preCreate = Date.now();\n","        stream = await createDom();\n","\n","        var preShow = Date.now();\n","        if (label != \"\") {\n","            labelElement.innerHTML = label;\n","        }\n","\n","        if (imgData != \"\") {\n","            var videoRect = video.getClientRects()[0];\n","            imgElement.style.top = videoRect.top + \"px\";\n","            imgElement.style.left = videoRect.left + \"px\";\n","            imgElement.style.width = videoRect.width + \"px\";\n","            imgElement.style.height = videoRect.height + \"px\";\n","            imgElement.src = imgData;\n","        }\n","\n","        var preCapture = Date.now();\n","        var result = await new Promise((resolve, reject) => pendingResolve = resolve);\n","        shutdown = false;\n","\n","        return {\n","            'create': preShow - preCreate,\n","            'show': preCapture - preShow,\n","            'capture': Date.now() - preCapture,\n","            'img': result,\n","        };\n","    }\n","    ''')\n","    display(js)\n","\n","def take_photo(label, img_data):\n","    data = eval_js(f'takePhoto(\"{label}\", \"{img_data}\")')\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 0.3. Define Python functions to"],"metadata":{"id":"pUYfZKNlhSFn"}},{"cell_type":"code","metadata":{"id":"A0ZgJiQBskDt"},"source":["def js_response_to_image(js_response) -> Image.Image:\n","    _, b64_str = js_response['img'].split(',')\n","    jpeg_bytes = b64decode(b64_str)\n","    image = Image.open(io.BytesIO(jpeg_bytes))\n","    return image\n","\n","def turn_non_black_pixels_visible(rgba_compatible_array: np.ndarray) -> np.ndarray:\n","    rgba_compatible_array[:, :, 3] = (rgba_compatible_array.max(axis=2) > 0).astype(int) * 255\n","    return rgba_compatible_array\n","\n","def black_transparent_rgba_canvas(w, h) -> np.ndarray:\n","    return np.zeros([w, h, 4], dtype=np.uint8)\n","\n","def draw_annotations_on_transparent_bg(detection_result: Results) -> Image.Image:\n","    black_rgba_canvas = black_transparent_rgba_canvas(*detection_result.orig_shape)\n","    transparent_canvas_with_boxes_invisible = detection_result.plot(font='verdana', masks=False, img=black_rgba_canvas)\n","    transparent_canvas_with_boxes_visible = turn_non_black_pixels_visible(transparent_canvas_with_boxes_invisible)\n","    image = Image.fromarray(transparent_canvas_with_boxes_visible, 'RGBA')\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIlKEQ3ruDCw"},"source":["## 1. Perform real-time object detection in webcam stream"]},{"cell_type":"code","metadata":{"id":"hZi6NXSDyAY6","collapsed":true},"source":["start_stream()\n","img_data = ''\n","while True:\n","    js_response = take_photo('Capturing...', img_data)\n","    if not js_response:\n","        break\n","\n","    captured_img = js_response_to_image(js_response)\n","\n","    # Ajustando a chamada para o modelo YOLOv8\n","    for detection_result in PRE_TRAINED_MODEL(\n","            source=np.array(captured_img),\n","            imgsz=640,  # Ajuste o tamanho da imagem para melhorar a performance\n","            conf=0.4,   # Ajuste o threshold de confiança (conf-thres)\n","            iou=0.4,    # Ajuste o threshold de IoU (iou-thres)\n","            verbose= False):\n","\n","        # Desenhar as anotações nas detecções\n","        annotations_img = draw_annotations_on_transparent_bg(detection_result)\n","\n","        # Converter a imagem anotada para base64 para exibição\n","        with io.BytesIO() as buffer:\n","            annotations_img.save(buffer, format='png')\n","            img_as_base64_str = str(b64encode(buffer.getvalue()), 'utf-8')\n","            img_data = f'data:image/png;base64,{img_as_base64_str}'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Uma imagem"],"metadata":{"id":"HCx7xn_GLH46"}},{"cell_type":"code","source":["# Importar bibliotecas necessárias\n","from PIL import Image, ImageDraw, ImageFont\n","import io\n","import numpy as np\n","from ultralytics import YOLO\n","import matplotlib.pyplot as plt\n","\n","# Caminho do modelo treinado\n","model_path = \"/content/gdrive/MyDrive/Sistema_de_Visão/yolov8/Cashew_nut/Train_CashewNut/runs/detect/train/weights/best.pt\"\n","PRE_TRAINED_MODEL = YOLO(model_path)\n","\n","# Função para carregar e processar a imagem\n","def load_image(image_path):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    return img\n","\n","# Função para executar o modelo e exibir resultados\n","def detect_and_display(image_path, model):\n","    # Carregar a imagem\n","    img = load_image(image_path)\n","\n","    # Realizar detecção\n","    results = model(img)\n","\n","    # Desenhar as detecções na imagem\n","    img_with_detections = img.copy()\n","    draw = ImageDraw.Draw(img_with_detections)\n","\n","    # Define uma fonte padrão para o texto (ou usa a fonte do sistema)\n","    try:\n","        font = ImageFont.truetype(\"arial.ttf\", 16)\n","    except IOError:\n","        font = ImageFont.load_default()\n","\n","    for result in results:\n","        for box in result.boxes:\n","            x1, y1, x2, y2 = box.xyxy[0].numpy()  # Coordenadas do bounding box\n","            label = int(box.cls.item())  # Classe\n","            conf = float(box.conf.item())  # Confiança\n","\n","            # Definir cor com base na classe\n","            color = \"green\" if label == 1 else \"red\"\n","            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n","\n","            # Texto e fundo do texto\n","            text = f\"{label}: {conf:.2f}\"\n","            text_bbox = draw.textbbox((x1, y1), text, font=font)\n","            text_width = text_bbox[2] - text_bbox[0]\n","            text_height = text_bbox[3] - text_bbox[1]\n","            text_background = (x1, y1 - text_height, x1 + text_width, y1)\n","            draw.rectangle(text_background, fill=color)\n","            draw.text((x1, y1 - text_height), text, fill=\"white\", font=font)\n","\n","    # Exibir imagem com detecções usando Matplotlib\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(img_with_detections)\n","    plt.axis(\"off\")  # Remover eixos para uma melhor visualização\n","    plt.show()\n","\n","# Definir caminho da imagem e executar detecção\n","image_path = \"/content/gdrive/MyDrive/Sistema_de_Visão/yolov8/Cashew_nut/Train_CashewNut/data/images/val/WIN_20241001_11_41_15_Pro.jpg\"  # Caminho da imagem enviada\n","detect_and_display(image_path, PRE_TRAINED_MODEL)\n"],"metadata":{"id":"EslE7l9dKph6","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tentativa real time extra"],"metadata":{"id":"KHUdFzDbLOig"}},{"cell_type":"code","source":["from google.colab import output\n","from base64 import b64decode\n","import IPython\n","from PIL import Image\n","import io\n","\n","# Código JavaScript para capturar a imagem\n","def take_photo():\n","    js = \"\"\"\n","    async function takePhoto() {\n","      const div = document.createElement('div');\n","      const video = document.createElement('video');\n","      const canvas = document.createElement('canvas');\n","      const button = document.createElement('button');\n","      button.textContent = 'Tirar Foto';\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      div.appendChild(button);\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Captura a imagem ao clicar no botão\n","      button.onclick = () => {\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getTracks().forEach(track => track.stop());\n","        div.remove();\n","        const dataUrl = canvas.toDataURL('image/jpeg', 0.8);\n","        google.colab.kernel.invokeFunction('notebook.process_image', [dataUrl], {});\n","      };\n","    }\n","    takePhoto();\n","    \"\"\"\n","    display(IPython.display.Javascript(js))\n","\n","# Chame a função para capturar a imagem\n","take_photo()\n"],"metadata":{"collapsed":true,"id":"cLbF6hgBKWuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Função para processar imagem capturada\n","def process_image(js_data):\n","    # Decodificar a imagem\n","    img_bytes = b64decode(js_data.split(',')[1])\n","    img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n","\n","    img = img.resize((640, 640))  # Ajuste o tamanho da imagem para algo mais eficiente\n","\n","    # Processar imagem com YOLO\n","    results = PRE_TRAINED_MODEL(source=np.array(img))  # Adicionar thresholds aqui\n","    annotated_img = draw_annotations_on_transparent_bg(results[0])\n","\n","    # Exibir resultado\n","    annotated_img.show()\n","\n"],"metadata":{"id":"ihgLxOFeJ4qG"},"execution_count":null,"outputs":[]}]}